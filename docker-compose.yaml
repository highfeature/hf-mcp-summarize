services:
  server:
    build: .
    environment:
      # change with the LLM you want to use for summarize
      - MODEL=hf-tool-llama3.2-3b-32k
      # change the URL of Ollama server
      - MODEL_URL=http://0.0.0.0:11434/
      # change the 0.0.0.0:18990 not working for now when full docker to
      # the IP address of sentry-nginx-1 and it's port.
      # - SENTRY_URL=http://a87a15429de8e0c6e17217403ece2c13@0.0.0.0:18990/2
      - SENTRY_URL=http://a87a15429de8e0c6e17217403ece2c13@172.31.0.69:80/2
    networks: 
      - sentry_default
    ports:
      - 19140:8000
    volumes:
      # If y use remote folder as volume, y will need to copy manually files in it.
      # - /home/a/docker-data/MCP/hf-mcp-summarizer:/app
      - hf-mcp-summarizer:/app
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://0.0.0.0:8000/health-check || exit 1"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

volumes:
  hf-mcp-summarizer:

networks:
  sentry_default:
    external: true
